{"cells":[{"cell_type":"markdown","metadata":{},"source":["# WebScraping"]},{"cell_type":"markdown","metadata":{},"source":["This is the code used for webscrapping. It can be compiled directly on collab notebook (Goople). We deliberately compile it in small steps because it is very slow when all the letters are entered at once. The code adds to the file each time a letter is entered. Once all the letters have been run through, the file can be downloaded and used in future code."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KNsRSAl7IPgq"},"outputs":[],"source":["import requests\n","from bs4 import BeautifulSoup\n","import csv\n","\n","def scrape_tajine_qui_parle(lettre):\n","    url = \"https://tajinequiparle.com/en/english-moroccan-arabic-dictionary/\"+ lettre +\"/\"\n","\n","    # Retrieving page content\n","    response = requests.get(url)\n","    soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","    # Searching for items using the \"glossary-listing\" class\n","    links = soup.find_all(\"a\", class_=\"glossary-listing\")\n","\n","    # Initialising the list of URLs\n","    urls = []\n","\n","    # Browsing elements to extract links\n","    for link in links:\n","        href = link.get(\"href\")\n","        urls.append(href)\n","\n","    # Retrieve information on a word page\n","    def get_word_info(url):\n","        response = requests.get(url)\n","        soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","        word = soup.find(\"h2\").text.strip() if soup.find(\"h2\") else \"\"\n","\n","        natures = []\n","        meanings = []\n","        arabic_translations = []\n","        arabic_writings = []\n","\n","        for h3 in soup.find_all(\"h3\"):\n","            if h3.find(\"em\"):\n","                nature_info = h3.find('em').text.strip()\n","                natures.append(nature_info)\n","\n","        if natures == []: natures.append('')\n","\n","        for h5 in soup.find_all(\"h5\"):\n","            arabic_text = h5.text.strip().split(\"[\", 1)\n","            if len(arabic_text) > 1:\n","                arabic_writing = arabic_text[1].split(\"]\")[0].strip()\n","            else:\n","                arabic_writing = \"\"\n","            meaning_text = h5.text.strip().split(\"(\", 1)\n","            if len(meaning_text) > 1:\n","                meaning = meaning_text[1].split(\")\")[0].strip()\n","            else:\n","                meaning = \"\"\n","            arabic_translation = \"\"\n","            arabic_translation = h5.find('q').text.strip() if h5.find('q') else(\"\")\n","            meanings.append(meaning)\n","            arabic_translations.append(arabic_translation)\n","            arabic_writings.append(arabic_writing)\n","        return word, natures, meanings, arabic_translations, arabic_writings\n","\n","    nom_fichier_csv = \"concatenated_words.csv\"\n","\n","    # Open a CSV file to append data\n","    with open(nom_fichier_csv, 'a', newline='', encoding='utf-8') as csvfile:\n","        fieldnames = ['Word', 'Nature', 'Arabic_Translation', 'Arabic_Writing', 'Meaning', 'Translation']\n","        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","\n","        # Browse URLs to retrieve information about each word\n","        for url in urls:\n","            word, natures, meanings, arabic_translations, arabic_writings = get_word_info(\"https://tajinequiparle.com\" + url)\n","            for i in range(len(meanings)):\n","                meaning_split = meanings[i].split(\" \", 1)\n","                if len(meaning_split) > 1:\n","                    meaning = meaning_split[1]\n","                else:\n","                    meaning = meanings[i]\n","                writer.writerow({'Word': word, 'Nature': natures[i if i < len(natures) else -1],\n","                                 'Arabic_Translation': arabic_translations[i],\n","                                 'Arabic_Writing': arabic_writings[i], 'Meaning': meaning,\n","                                 'Translation': meaning_split[0]})\n","\n","nom_fichier_csv = \"concatenated_words.csv\"\n","    # Open a CSV file to write data\n","with open(nom_fichier_csv, 'w', newline='', encoding='utf-8') as csvfile:\n","    fieldnames = ['Word', 'Nature', 'Arabic_Translation', 'Arabic_Writing', 'Meaning', 'Translation']\n","    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n","\n","scrape_tajine_qui_parle(\"a\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sDcwQJh-OUeG"},"outputs":[],"source":["scrape_tajine_qui_parle(\"b\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BOo5E4RfO82O"},"outputs":[],"source":["letters = ['c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k']\n","for letter in letters:\n","    scrape_tajine_qui_parle(letter)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yzZ8RsJcQw54"},"outputs":[],"source":["letters = ['l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u']\n","for letter in letters:\n","    scrape_tajine_qui_parle(letter)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Z94t8bABRCqS"},"outputs":[],"source":["letters = ['v', 'w', 'x', 'y', 'z']\n","for letter in letters:\n","    scrape_tajine_qui_parle(letter)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FqSG3vYJOtSA"},"outputs":[],"source":["\"\"\"alphabet_anglais = ['a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n","\n","print(alphabet_anglais)\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QSxhRyQfIlm9"},"outputs":[],"source":["\"\"\"letters = alphabet_anglais\n","\n","for letter in letters:\n","    scrape_tajine_qui_parle(letter)\"\"\""]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNxTgMfk3gOTCBVDPn5TTiq","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
